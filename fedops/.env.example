# FedOps Environment Configuration

# Database
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/fedops

# External APIs
SAM_API_KEY=your_sam_api_key_here

# AI/LLM Provider Configuration
# Choose one: gemini, openai, openrouter
LLM_PROVIDER=openrouter

# API Keys (set the one matching your LLM_PROVIDER)
GOOGLE_API_KEY=your_google_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Model Selection
# OpenRouter Models:
#   - deepseek/deepseek-r1 (Recommended: Strong structured JSON extraction)
#   - google/gemini-3-pro-preview (Fast analysis, PDF support)
#   - google/gemini-2.0-flash-exp (Very fast, efficient)
#   - qwen/qwen-2.5-32b-instruct (High accuracy extraction)
#   - mistralai/mistral-large-2 (Tool calling, schema support)
#   - anthropic/claude-3.5-sonnet (Excellent reasoning)
# Gemini Models (when LLM_PROVIDER=gemini):
#   - gemini-2.5-flash
#   - gemini-2.5-pro
#   - gemini-3-pro-preview
# OpenAI Models (when LLM_PROVIDER=openai):
#   - gpt-4o
#   - gpt-4o-mini
LLM_MODEL=deepseek/deepseek-r1

# Model Parameters
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=4096
LLM_MAX_RETRIES=3
LLM_RETRY_DELAY=1.0

# Fallback model if primary fails
LLM_FALLBACK_MODEL=google/gemini-2.0-flash-exp

# Upload Directory
UPLOAD_DIR=uploads
